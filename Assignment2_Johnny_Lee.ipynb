{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale=True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "\n",
    "import numpy as np\n",
    "# import cupy as xp\n",
    "\n",
    "import pyopencl as cl\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = cl.get_platforms()\n",
    "devices = platform[0].get_devices()\n",
    "context = cl.Context(devices)\n",
    "queue = cl.CommandQueue(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_matmul = \"\"\"\n",
    "#define TSM 128                // The tile-size in dimension M\n",
    "#define TSN 128                // The tile-size in dimension N\n",
    "#define TSK 16                 // The tile-size in dimension K\n",
    "#define WPTM 8                 // The work-per-thread in dimension M\n",
    "#define WPTN 8                 // The work-per-thread in dimension N\n",
    "#define RTSM (TSM/WPTM)        // The reduced tile-size in dimension M\n",
    "#define RTSN (TSN/WPTN)        // The reduced tile-size in dimension N\n",
    "#define LPTA ((TSK*TSM)/(RTSM*RTSN)) // Loads-per-thread for A\n",
    "#define LPTB ((TSK*TSN)/(RTSM*RTSN)) // Loads-per-thread for B\n",
    "\n",
    "// Use 2D register blocking (further increase in work per thread)\n",
    "__kernel void matmul(const int M, const int N, const int K,\n",
    "                      const __global float* A,\n",
    "                      const __global float* B,\n",
    "                      __global float* C) {\n",
    "    \n",
    "    // Thread identifiers\n",
    "    const int tidm = get_local_id(0); // Local row ID (max: TSM/WPTM)\n",
    "    const int tidn = get_local_id(1); // Local col ID (max: TSN/WPTN)\n",
    "    const int offsetM = TSM*get_group_id(0); // Work-group offset\n",
    "    const int offsetN = TSN*get_group_id(1); // Work-group offset\n",
    " \n",
    "    // Local memory to fit a tile of A and B\n",
    "    __local float Asub[TSK][TSM];\n",
    "    __local float Bsub[TSN][TSK+2];\n",
    " \n",
    "    // Allocate register space\n",
    "    float Areg;\n",
    "    float Breg[WPTN];\n",
    "    float acc[WPTM][WPTN];\n",
    " \n",
    "    // Initialise the accumulation registers\n",
    "    for (int wm=0; wm<WPTM; wm++) {\n",
    "        for (int wn=0; wn<WPTN; wn++) {\n",
    "            acc[wm][wn] = 0.0f;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Loop over all tiles\n",
    "    int numTiles = K/TSK;\n",
    "    for (int t=0; t<numTiles; t++) {\n",
    " \n",
    "        // Load one tile of A and B into local memory\n",
    "        for (int la=0; la<LPTA; la++) {\n",
    "            int tid = tidn*RTSM + tidm;\n",
    "            int id = la*RTSN*RTSM + tid;\n",
    "            int row = id % TSM;\n",
    "            int col = id / TSM;\n",
    "            int tiledIndex = TSK*t + col;\n",
    "            Asub[col][row] = A[tiledIndex*M + offsetM + row];\n",
    "            Bsub[row][col] = B[tiledIndex*N + offsetN + row];\n",
    "        }\n",
    "        \n",
    "        // Synchronise to make sure the tile is loaded\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    " \n",
    "        // Loop over the values of a single tile\n",
    "        for (int k=0; k<TSK; k++) {\n",
    " \n",
    "            // Cache the values of Bsub in registers\n",
    "            for (int wn=0; wn<WPTN; wn++) {\n",
    "                int col = tidn + wn*RTSN;\n",
    "                Breg[wn] = Bsub[col][k];\n",
    "            }\n",
    " \n",
    "            // Perform the computation\n",
    "            for (int wm=0; wm<WPTM; wm++) {\n",
    "                int row = tidm + wm*RTSM;\n",
    "                Areg = Asub[k][row];\n",
    "                for (int wn=0; wn<WPTN; wn++) {\n",
    "                    acc[wm][wn] += Areg * Breg[wn];\n",
    "                }\n",
    "            }\n",
    "        }\n",
    " \n",
    "        // Synchronise before loading the next tile\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "    }\n",
    " \n",
    "    // Store the final results in C\n",
    "    for (int wm=0; wm<WPTM; wm++) {\n",
    "        int globalRow = offsetM + tidm + wm*RTSM;\n",
    "        for (int wn=0; wn<WPTN; wn++) {\n",
    "            int globalCol = offsetN + tidn + wn*RTSN;\n",
    "            C[globalCol*M + globalRow] = acc[wm][wn];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_matmul = \"\"\"\n",
    "#pragma OPENCL EXTENSION cl_khr_fp64: enable\n",
    "\n",
    "__kernel void matmul(__global float* C, \n",
    "          __global float* A, \n",
    "          __global float* B, \n",
    "          const int wA, const int wB){\n",
    "  \n",
    "   int tile_x = get_global_id(0); \n",
    "   int tile_y = get_global_id(1);\n",
    " \n",
    "   // value stores the element that is computed by the thread\n",
    "   float value = 0;\n",
    "   for (int k = 0; k < wA; ++k){\n",
    "      float elementA = A[tile_y * wA + k];\n",
    "      float elementB = B[k * wB + tile_x];\n",
    "      value += elementA * elementB;\n",
    "\n",
    "      barrier(CLK_LOCAL_MEM_FENCE);\n",
    "   }\n",
    " \n",
    "   // Write the matrix to device memory each thread writes one element\n",
    "   C[tile_y * wA + tile_x] = value;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = cl.Program(context, gpu_matmul).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.int32(2**12)\n",
    "m = n\n",
    "k = n\n",
    "\n",
    "a = np.random.rand(m, n).astype(np.float32)\n",
    "b = np.random.rand(n, k).astype(np.float32)\n",
    "c = np.empty_like(np.random.rand(m,k).astype(np.float32))\n",
    "\n",
    "mf = cl.mem_flags\n",
    "a_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = a)\n",
    "b_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = b)\n",
    "c_buf = cl.Buffer(context, mf.WRITE_ONLY, c.nbytes)\n",
    "\n",
    "\n",
    "TS = 16\n",
    "local = (TS, TS)\n",
    "global_size = (m, n)\n",
    "\n",
    "# local = tuple(map(int, local))\n",
    "# global_size = tuple(map(int, global_size))\n",
    "\n",
    "\n",
    "kernel = program.matmul\n",
    "\n",
    "kernel.set_arg(0, c_buf)\n",
    "kernel.set_arg(1, a_buf)\n",
    "kernel.set_arg(2, b_buf)\n",
    "kernel.set_arg(3, m)\n",
    "kernel.set_arg(4, k)\n",
    "# kernel.set_arg(5, c_buf)\n",
    "\n",
    "event = cl.enqueue_nd_range_kernel(queue, kernel, global_size, local)\n",
    "\n",
    "# event = program.matmul(queue, global_size, local,\n",
    "#                         np.int32(a.shape[1]), np.int32(b.shape[1]), np.int32(b.shape[0]),\n",
    "#                         a_buf, b_buf, c_buf)\n",
    "\n",
    "event.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1004.858  , 1012.63184, 1006.4273 , ..., 1015.6985 ,  999.89984,\n",
       "        1030.3223 ],\n",
       "       [1036.9243 , 1034.8726 , 1042.5879 , ..., 1045.3645 , 1026.7124 ,\n",
       "        1056.0624 ],\n",
       "       [1022.2027 , 1016.8986 , 1020.7775 , ..., 1028.5984 , 1021.4653 ,\n",
       "        1043.6118 ],\n",
       "       ...,\n",
       "       [1014.9922 , 1003.9858 , 1014.8939 , ..., 1016.62616, 1008.9029 ,\n",
       "        1038.7614 ],\n",
       "       [1028.1812 , 1014.7839 , 1019.60077, ..., 1022.00793, 1022.5033 ,\n",
       "        1039.1003 ],\n",
       "       [1022.1451 , 1007.8258 , 1018.5775 , ..., 1018.6975 , 1021.04156,\n",
       "        1039.0576 ]], dtype=float32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.enqueue_copy(queue, c, c_buf)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1004.85785 1012.63104 1006.4269  ... 1015.6977   999.89886 1030.3209 ]\n",
      " [1036.9236  1034.873   1042.5878  ... 1045.3646  1026.7124  1056.0621 ]\n",
      " [1022.204   1016.8974  1020.77814 ... 1028.5984  1021.4633  1043.615  ]\n",
      " ...\n",
      " [1014.9924  1003.9858  1014.895   ... 1016.6276  1008.9037  1038.7601 ]\n",
      " [1028.1803  1014.782   1019.6004  ... 1022.0074  1022.5029  1039.1    ]\n",
      " [1022.14465 1007.82684 1018.57623 ... 1018.697   1021.04034 1039.0581 ]]\n",
      "[[1004.85785 1012.63104 1006.4269  ... 1015.6977   999.89886 1030.3209 ]\n",
      " [1036.9236  1034.873   1042.5878  ... 1045.3646  1026.7124  1056.0621 ]\n",
      " [1022.204   1016.8974  1020.77814 ... 1028.5984  1021.4633  1043.615  ]\n",
      " ...\n",
      " [1014.9924  1003.9858  1014.895   ... 1016.6276  1008.9037  1038.7601 ]\n",
      " [1028.1803  1014.782   1019.6004  ... 1022.0074  1022.5029  1039.1    ]\n",
      " [1022.14465 1007.82684 1018.57623 ... 1018.697   1021.04034 1039.0581 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(a,b))\n",
    "print(np.matmul(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(np.matmul(a,b), c, decimal=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_matmul = \"\"\"\n",
    "#define BLOCK_SIZE 32\n",
    "#define global_idx(x_idx, y_idx, m) (x_idx * m + y_idx)\n",
    "\n",
    "#define WPT 8\n",
    "#define RBLOCK_SIZE (BLOCK_SIZE/WPT)\n",
    "\n",
    "// -- Uses NDRange Kernel with Local Memory and 2D Register tiling\n",
    "// M, N, P can be arbitrary sizes\n",
    "__kernel __attribute__((reqd_work_group_size(BLOCK_SIZE / WPT, BLOCK_SIZE / WPT, 1)))\n",
    "void matmul(\n",
    "      __global float* restrict A,\n",
    "      __global float* restrict B,\n",
    "      __global float* restrict C,\n",
    "      __const int M,\n",
    "      __const int N,\n",
    "      __const int P,\n",
    "      __const int M_,\n",
    "      __const int N_,\n",
    "      __const int P_)\n",
    "{\n",
    "    const int row = get_local_id(0);\n",
    "    const int col = get_local_id(1);\n",
    "    const int m = BLOCK_SIZE*get_group_id(0) + row;\n",
    "    const int p = BLOCK_SIZE*get_group_id(1) + col;\n",
    "    __local float A_local[BLOCK_SIZE][BLOCK_SIZE];\n",
    "    __local float B_local[BLOCK_SIZE][BLOCK_SIZE];\n",
    "    \n",
    "    float Areg;\n",
    "    float Breg[WPT];\n",
    "    float acc[WPT][WPT];\n",
    "    for(int wm=0; wm<WPT; wm++){\n",
    "        for(int wn=0; wn<WPT; wn++){\n",
    "            acc[wm][wn] = 0.0f;\n",
    "        }\n",
    "    }\n",
    "    const int numTiles = N_/BLOCK_SIZE;\n",
    "    #pragma unroll\n",
    "    for (int t=0; t<numTiles; t++) {\n",
    "        for (int wm=0; wm<WPT; wm++){\n",
    "            for (int wn=0; wn<WPT; wn++){\n",
    "                const int r = BLOCK_SIZE*t + row;\n",
    "                const int c = BLOCK_SIZE*t + col;\n",
    "                if(((m + wm*RBLOCK_SIZE) < M) && ((c + wn*RBLOCK_SIZE) < N)){\n",
    "                    A_local[row + wm*RBLOCK_SIZE][col + wn*RBLOCK_SIZE] = A[(m + wm*RBLOCK_SIZE)*N + (c + wn*RBLOCK_SIZE)];\n",
    "                } else {\n",
    "                    A_local[row + wm*RBLOCK_SIZE][col + wn*RBLOCK_SIZE] = 0.0;\n",
    "                }\n",
    "\n",
    "                if(((p + wn*RBLOCK_SIZE) < P) && ((r + wm*RBLOCK_SIZE) < N)){\n",
    "                    B_local[row + wm*RBLOCK_SIZE][col + wn*RBLOCK_SIZE] = B[(r + wm*RBLOCK_SIZE)*P + (p + wn*RBLOCK_SIZE)];\n",
    "                } else {\n",
    "                    B_local[row + wm*RBLOCK_SIZE][col + wn*RBLOCK_SIZE] = 0.0;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "        #pragma unroll BLOCK_SIZE\n",
    "        for (int k=0; k<BLOCK_SIZE; k++){\n",
    "            for (int wn=0; wn<WPT; wn++){\n",
    "                Breg[wn] = B_local[k][col + wn*RBLOCK_SIZE];\n",
    "            }\n",
    "            for (int wm=0; wm<WPT; wm++){\n",
    "                Areg = A_local[row + wm*RBLOCK_SIZE][k];\n",
    "                for (int wn=0; wn<WPT; wn++){\n",
    "                    acc[wm][wn] += Areg * Breg[wn];\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "    }\n",
    "    for (int wm=0; wm<WPT; wm++){\n",
    "        for (int wn=0; wn<WPT; wn++){\n",
    "            if(((m + wm*RBLOCK_SIZE) < M) && ((p + wn*RBLOCK_SIZE) < P)){\n",
    "                C[(m + wm*RBLOCK_SIZE)*P + (p + wn*RBLOCK_SIZE)] = acc[wm][wn];\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['PYOPENCL_COMPILER_OUTPUT'] = '0'\n",
    "# os.environ['PYOPENCL_CTX'] = '0:1'\n",
    "\n",
    "class Timer:\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end = time.time()\n",
    "        self.interval = self.end - self.start\n",
    "        \n",
    "def roundUp(numToRound, multiple):\n",
    "    if (multiple == 0):\n",
    "        return numToRound\n",
    "    remainder = numToRound % multiple\n",
    "    if (remainder == 0):\n",
    "        return numToRound\n",
    "    return numToRound + multiple - remainder\n",
    "BLOCK_SIZE = 32\n",
    "WPT = 8\n",
    "\n",
    "mult = 2\n",
    "m, n, k = 3*(10**mult), 4*(10**mult), 5*(10**mult)\n",
    "m_, n_, k_ = roundUp(m, BLOCK_SIZE), roundUp(n, BLOCK_SIZE), roundUp(k, BLOCK_SIZE)\n",
    "a = np.random.randn(m, n).astype(np.float32)\n",
    "b = np.random.randn(n, k).astype(np.float32)\n",
    "\n",
    "program = cl.Program(context, gpu_matmul).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np:  0.0020112991333007812\n",
      "py:  0.0030014514923095703\n",
      "cl:  0.007557868957519531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((300, 500), 300, 400, 500)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_times, py_times, cl_times = [], [], []\n",
    "\n",
    "# ctx = cl.create_some_context()\n",
    "# queue = cl.CommandQueue(ctx)\n",
    "mf = cl.mem_flags\n",
    "a_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = a)\n",
    "b_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = b)\n",
    "\n",
    "start = time.time()\n",
    "c = a.dot(b)\n",
    "end = time.time()\n",
    "print('np: ', end - start)\n",
    "np_times.append(end - start)\n",
    "start = time.time()\n",
    "c = a @ b\n",
    "end = time.time()\n",
    "print('py: ', end - start)\n",
    "py_times.append(end - start)\n",
    "\n",
    "c_res = np.zeros_like(c)\n",
    "c_buf = cl.Buffer(context, mf.WRITE_ONLY, c_res.nbytes)\n",
    "c.shape\n",
    "\n",
    "with Timer() as t:\n",
    "    event = program.matmul(queue, (m_ // WPT , k_ // WPT), (BLOCK_SIZE // WPT, BLOCK_SIZE // WPT), \n",
    "                     a_buf, b_buf, c_buf,\n",
    "                     np.int32(m), np.int32(n), np.int32(k),\n",
    "                     np.int32(m_), np.int32(n_), np.int32(k_))\n",
    "    event.wait()\n",
    "print('cl: ', t.interval)\n",
    "cl_times.append(t.interval)\n",
    "cl.enqueue_copy(queue, c_res, c_buf)\n",
    "\n",
    "c_res.shape, m, n, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(c_res, c, decimal=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpcpy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
