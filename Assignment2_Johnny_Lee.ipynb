{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale=True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "\n",
    "import pyopencl as cl\n",
    "import numpy as np\n",
    "import scipy.interpolate as intrp\n",
    "from scipy import stats\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import patsy # for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multiplicand_for_beta(X, weights = 1, df = 1):\n",
    "  \"\"\"\n",
    "  Computes inv(XtWX+lambdaI), which can then give us \n",
    "  beta via the simple inv(XtWX+lambdaI)@XtWg\n",
    "  \"\"\"\n",
    "  X_tilde = (X.T*np.sqrt(weights)).T\n",
    "  # QR decompose X\n",
    "  R = np.linalg.qr(X_tilde)[1]\n",
    "  # Find smoothing parameter\n",
    "  if X.shape[1] <= df:\n",
    "    k = 0\n",
    "  else:\n",
    "    inv_eig =  np.linalg.eigvalsh(R @ R.T)\n",
    "    k = 0.000001 # Any small value would do\n",
    "    # Find Newton-Rhapson step\n",
    "    def find_step(k):\n",
    "      h = 1+k/inv_eig # for performance\n",
    "      fx = np.sum(1/h)-1\n",
    "      dfdx = np.sum(-1/(inv_eig * (h**2)))\n",
    "      delta = -fx/dfdx\n",
    "      return delta\n",
    "    \n",
    "    # Find root\n",
    "    delta = 3. # Any large value would do\n",
    "    while delta > 1e-7: \n",
    "      delta = find_step(k)\n",
    "      k += delta\n",
    "\n",
    "  XtWX = R.T @ R\n",
    "  # add lambdaI\n",
    "  d = np.einsum('ii->i', XtWX)\n",
    "  d += k\n",
    "  # Final result\n",
    "  return np.linalg.inv(XtWX)\n",
    "\n",
    "def roundUp(numToRound, multiple):\n",
    "    if (multiple == 0):\n",
    "        return numToRound\n",
    "    remainder = numToRound % multiple\n",
    "    if (remainder == 0):\n",
    "        return numToRound\n",
    "    return numToRound + multiple - remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end = time.time()\n",
    "        self.interval = self.end - self.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 15])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rows = 1000\n",
    "n_learners = 100\n",
    "n_effects = 2\n",
    "w = np.ones(n_rows, dtype = np.float32)\n",
    "# xp.random.multinomial(n, [1/n]*n, size=1).reshape((n, ))\n",
    "\n",
    "#---- Generate data\n",
    "# Add sorting if you want to plot one of the functions\n",
    "independent_variables = \\\n",
    "  [np.random.default_rng(i).uniform(0, 1, n_rows) for i in range(n_learners)]\n",
    "\n",
    "# Simulate f(x) = 7 + 10*sin(2 pi x) \n",
    "intercept = 7\n",
    "\n",
    "mu = intercept\n",
    "\n",
    "effect_index = np.random.default_rng(111).integers(\n",
    "    0, n_learners, size = n_effects, \n",
    "    dtype = np.int32)\n",
    "for i in effect_index:\n",
    "  mu += 10*np.sin(independent_variables[i]*2*np.pi) + independent_variables[i]\n",
    "\n",
    "epsilon = np.random.default_rng(777).normal(size = n_rows, scale = .001)\n",
    "y = mu + epsilon\n",
    "effect_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Compute basis matrices\n",
    "raw_design_matrices = \\\n",
    "  [patsy.dmatrix(\n",
    "      \"bs(x, df=32, degree=3, include_intercept=True)-1\", \n",
    "      {\"x\": x}) for x in independent_variables]\n",
    "\n",
    "# Centre\n",
    "center_function = lambda x: x - x.mean()\n",
    "design_matrices = \\\n",
    "  [np.apply_along_axis(center_function, 0, B).astype(np.float32) for B in raw_design_matrices]\n",
    "\n",
    "# B_center = np.asarray(B_center).astype(np.float32)\n",
    "# # y_center = (y - np.mean(y, axis=0))\n",
    "# # plt.subplot(1,2,1)\n",
    "\n",
    "# plt.plot(X[0], y)\n",
    "# plt.title('B-spline basis')\n",
    "\n",
    "multiplicands_for_beta = [\n",
    "    compute_multiplicand_for_beta(X, weights = w) for X in design_matrices\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_matmul = \"\"\"\n",
    "#pragma OPENCL EXTENSION cl_khr_fp64: enable\n",
    "#ifndef USE_DOUBLE\n",
    "#define USE_DOUBLE 0\n",
    "#endif\n",
    "\n",
    "#if USE_DOUBLE\n",
    "#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n",
    "typedef double scalar_t;\n",
    "#else\n",
    "typedef float scalar_t;\n",
    "#endif\n",
    "\n",
    "#define BLOCK_SIZE 16\n",
    "#define global_idx(x_idx, y_idx, m) (x_idx * m + y_idx)\n",
    "\n",
    "#define WPT 8\n",
    "#define RBLOCK_SIZE (BLOCK_SIZE/WPT)\n",
    "\n",
    "#define ROW_DIM 0\n",
    "#define COL_DIM 1\n",
    "\n",
    "// -- Uses NDRange Kernel with Local Memory and 2D Register tiling\n",
    "// M, N, P can be arbitrary sizes\n",
    "__kernel __attribute__((reqd_work_group_size(BLOCK_SIZE / WPT, BLOCK_SIZE / WPT, 1)))\n",
    "void matmul(\n",
    "      __global float* restrict A,\n",
    "      __global float* restrict B,\n",
    "      __global float* restrict C,\n",
    "      __const int M,\n",
    "      __const int N,\n",
    "      __const int P,\n",
    "      __const int M_,\n",
    "      __const int N_,\n",
    "      __const int P_)\n",
    "{\n",
    "    const int row = get_local_id(0);\n",
    "    const int col = get_local_id(1);\n",
    "    const int m = BLOCK_SIZE*get_group_id(0) + row;\n",
    "    const int p = BLOCK_SIZE*get_group_id(1) + col;\n",
    "    __local float A_local[BLOCK_SIZE][BLOCK_SIZE];\n",
    "    __local float B_local[BLOCK_SIZE][BLOCK_SIZE];\n",
    "    \n",
    "    float Areg;\n",
    "    float Breg[WPT];\n",
    "    float acc[WPT][WPT];\n",
    "    for(int wm=0; wm<WPT; wm++){\n",
    "        for(int wn=0; wn<WPT; wn++){\n",
    "            acc[wm][wn] = 0.0f;\n",
    "        }\n",
    "    }\n",
    "    const int numTiles = N_/BLOCK_SIZE;\n",
    "    #pragma unroll\n",
    "    for (int t=0; t<numTiles; t++) {\n",
    "        for (int wm=0; wm<WPT; wm++){\n",
    "            for (int wn=0; wn<WPT; wn++){\n",
    "                const int r = BLOCK_SIZE*t + row;\n",
    "                const int c = BLOCK_SIZE*t + col;\n",
    "                if(((m + wm*RBLOCK_SIZE) < M) && ((c + wn*RBLOCK_SIZE) < N)){\n",
    "                    A_local[row + wm*RBLOCK_SIZE][col + wn*RBLOCK_SIZE] = A[(m + wm*RBLOCK_SIZE)*N + (c + wn*RBLOCK_SIZE)];\n",
    "                } else {\n",
    "                    A_local[row + wm*RBLOCK_SIZE][col + wn*RBLOCK_SIZE] = 0.0;\n",
    "                }\n",
    "\n",
    "                if(((p + wn*RBLOCK_SIZE) < P) && ((r + wm*RBLOCK_SIZE) < N)){\n",
    "                    B_local[row + wm*RBLOCK_SIZE][col + wn*RBLOCK_SIZE] = B[(r + wm*RBLOCK_SIZE)*P + (p + wn*RBLOCK_SIZE)];\n",
    "                } else {\n",
    "                    B_local[row + wm*RBLOCK_SIZE][col + wn*RBLOCK_SIZE] = 0.0;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "        #pragma unroll BLOCK_SIZE\n",
    "        for (int k=0; k<BLOCK_SIZE; k++){\n",
    "            for (int wn=0; wn<WPT; wn++){\n",
    "                Breg[wn] = B_local[k][col + wn*RBLOCK_SIZE];\n",
    "            }\n",
    "            for (int wm=0; wm<WPT; wm++){\n",
    "                Areg = A_local[row + wm*RBLOCK_SIZE][k];\n",
    "                for (int wn=0; wn<WPT; wn++){\n",
    "                    acc[wm][wn] += Areg * Breg[wn];\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "    }\n",
    "    for (int wm=0; wm<WPT; wm++){\n",
    "        for (int wn=0; wn<WPT; wn++){\n",
    "            if(((m + wm*RBLOCK_SIZE) < M) && ((p + wn*RBLOCK_SIZE) < P)){\n",
    "                C[(m + wm*RBLOCK_SIZE)*P + (p + wn*RBLOCK_SIZE)] = acc[wm][wn];\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__kernel void matmul_global(__global float* C, \n",
    "          __global float* A, \n",
    "          __global float* B, \n",
    "          const int wA, const int wB){\n",
    "  \n",
    "   int tile_x = get_global_id(0); \n",
    "   int tile_y = get_global_id(1);\n",
    " \n",
    "   // value stores the element that is computed by the thread\n",
    "   float value = 0;\n",
    "   for (int k = 0; k < wA; ++k){\n",
    "      float elementA = A[tile_y * wA + k];\n",
    "      float elementB = B[k * wB + tile_x];\n",
    "      value += elementA * elementB;\n",
    "\n",
    "      barrier(CLK_LOCAL_MEM_FENCE);\n",
    "   }\n",
    " \n",
    "   // Write the matrix to device memory each thread writes one element\n",
    "   C[tile_y * wA + tile_x] = value;\n",
    "}\n",
    "\n",
    "__kernel void matvecmul(int M,\n",
    "                        int N,\n",
    "                        const global float *A,\n",
    "                        const global float *x,\n",
    "                        global float *y)\n",
    "    {   \n",
    "        int i = get_global_id(0);\n",
    "        float acc = 0.0f;\n",
    "        for (int j=0; j<N; j++)\n",
    "        {\n",
    "            acc += A[M * j + i] * x[j];\n",
    "        }\n",
    "        y[i] = acc;\n",
    "}\n",
    "\n",
    "__kernel void gemv1(int m, int n,__global const scalar_t * a,__global const scalar_t * x,\n",
    "                    __global scalar_t * y){\n",
    "    scalar_t sum = 0.0f;\n",
    "    int i = get_global_id(0); // row index\n",
    "    for (int k=0;k<n;k++)\n",
    "        {\n",
    "        sum += a[i + m*k] * x[k];\n",
    "        }\n",
    "    y[i] = sum;\n",
    "}\n",
    "\n",
    "// GEMV2\n",
    "__kernel void gemv2(int m,int n, __global const float * a,\n",
    "                    __global const float * x,\n",
    "                    __global float * y\n",
    "                    ){\n",
    "\n",
    "  // Compute partial dot product\n",
    "  __local float work[16];\n",
    "  float sum = 0;\n",
    "  for (int k=get_global_id(COL_DIM);k<n;k+=get_global_size(COL_DIM))\n",
    "    {\n",
    "      sum += a[get_global_id(ROW_DIM)+m*k] * x[k];\n",
    "    }\n",
    "\n",
    "  // Each thread stores its partial sum in WORK\n",
    "  int rows = get_local_size(ROW_DIM); // rows in group\n",
    "  int cols = get_local_size(COL_DIM); // initial cols in group\n",
    "  int ii = get_local_id(ROW_DIM); // local row index in group, 0<=ii<rows\n",
    "  int jj = get_local_id(COL_DIM); // block index in column, 0<=jj<cols\n",
    "  work[ii+rows*jj] = sum;\n",
    "  barrier(CLK_LOCAL_MEM_FENCE); // sync group\n",
    "\n",
    "  // Reduce sums in log2(cols) steps\n",
    "  while ( cols > 1 )\n",
    "    {\n",
    "      cols >>= 1;\n",
    "      if (jj < cols) work[ii+rows*jj] += work[ii+rows*(jj+cols)];\n",
    "      barrier(CLK_LOCAL_MEM_FENCE); // sync group\n",
    "    }\n",
    "\n",
    "  // Write final result in Y\n",
    "  if ( jj == 0 ) y[get_global_id(ROW_DIM)] = work[ii];\n",
    "}\n",
    "\n",
    "// GEMV3\n",
    "__kernel void gemv3(int m,int n, __global const float * a,\n",
    "                    __global const float * x,\n",
    "                    __global float * y\n",
    "                    ){\n",
    "\n",
    "  // Compute partial dot product\n",
    "  __local float work[16];\n",
    "  float sum = 0;\n",
    "  for (int k=get_global_id(COL_DIM);k<n;k+=get_global_size(COL_DIM))\n",
    "    {\n",
    "      sum += a[get_global_id(ROW_DIM)+m*k] * x[k];\n",
    "    }\n",
    "\n",
    "  // Each thread stores its partial sum in WORK\n",
    "  int rows = get_local_size(ROW_DIM); // rows in group\n",
    "  int cols = get_local_size(COL_DIM); // initial cols in group\n",
    "  int ii = get_local_id(ROW_DIM); // local row index in group, 0<=ii<rows\n",
    "  int jj = get_local_id(COL_DIM); // block index in column, 0<=jj<cols\n",
    "  work[ii+rows*jj] = sum;\n",
    "  barrier(CLK_LOCAL_MEM_FENCE); // sync group\n",
    "\n",
    "  // Reduce sums in log2(cols) steps\n",
    "  while ( cols > 1 )\n",
    "    {\n",
    "      cols >>= 1;\n",
    "      if (jj < cols) work[ii+rows*jj] += work[ii+rows*(jj+cols)];\n",
    "      barrier(CLK_LOCAL_MEM_FENCE); // sync group\n",
    "    }\n",
    "\n",
    "  // Write final result in Y\n",
    "  if ( jj == 0 ) y[get_global_id(ROW_DIM)] = work[ii];\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = cl.get_platforms()\n",
    "devices = platform[0].get_devices()\n",
    "context = cl.Context(devices)\n",
    "queue = cl.CommandQueue(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = cl.Program(context, gpu_matmul).build()\n",
    "\n",
    "\n",
    "# Initialise data\n",
    "offset = np.average(y, weights = w)\n",
    "g = y-offset\n",
    "mstop = 100\n",
    "lr = 0.1 # Learning rate\n",
    "\n",
    "final_coefs = [np.zeros(X.shape[1], dtype = np.float32) for X in design_matrices]\n",
    "delta = [np.zeros(X.shape[1], dtype = np.float32) for X in design_matrices]\n",
    "eta = [np.zeros(X.shape[0], dtype = np.float32) for X in design_matrices]\n",
    "rss = np.zeros(len(design_matrices), dtype = np.float32)\n",
    "benchmark = np.empty((mstop, n_learners))\n",
    "benchmark_GPU = np.empty((mstop, n_learners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the part we need to have in opencl\n",
    "for m in range(mstop):\n",
    "  Wg = g*w\n",
    "  \n",
    "  # Expensive part of the function\n",
    "  for i in range(n_learners):\n",
    "  # for i in range(1):\n",
    "    # Per learner iterations\n",
    "    A = multiplicands_for_beta[i]\n",
    "    X = design_matrices[i]\n",
    "    \n",
    "    #== Compute runtime\n",
    "    start = time.time()\n",
    " \n",
    "    # Matrix multiplications\n",
    "    XtWg = X.T @ Wg # O(np)\n",
    "    # print(np.shape(X.T), np.shape(Wg))\n",
    "    # print(np.shape(XtWg))\n",
    "    delta[i] = lr*(A @ XtWg) # O(p^2) \n",
    "    \n",
    "    eta[i] = X @ delta[i] # O(np)\n",
    "    \n",
    "    #== Compute runtime\n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    benchmark[m,i]=t\n",
    "    \n",
    "    rss[i] = np.sum((g-eta[i])**2)\n",
    "\n",
    "  ind = np.argmin(rss)\n",
    "  # Update model\n",
    "  # print(np.shape(delta[ind]))\n",
    "  final_coefs[ind] += delta[ind]\n",
    "  g -= eta[ind]\n",
    "\n",
    "  benchmark.mean()\n",
    "  benchmark_GPU.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the part we need to have in opencl\n",
    "for m in range(mstop):\n",
    "  Wg = np.asarray((g*w)).astype(np.float32)\n",
    "  \n",
    "  # Expensive part of the function\n",
    "  for i in range(n_learners):\n",
    "  # for i in range(1):\n",
    "    # Per learner iterations\n",
    "    A = multiplicands_for_beta[i].astype(np.float32)\n",
    "    X = design_matrices[i].astype(np.float32)\n",
    "    \n",
    "    #== Compute runtime\n",
    "    # start = time.time()\n",
    " \n",
    "    # Matrix multiplications\n",
    "    # XtWg = X.T @ Wg # O(np)\n",
    "    a = (X.T).astype(np.float32)\n",
    "    b = Wg\n",
    "    m, n = np.shape(a)\n",
    "    k = 1\n",
    "    XtWg = np.empty(m).astype(np.float32)\n",
    "\n",
    "    mf = cl.mem_flags\n",
    "    a_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = a)\n",
    "    b_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = b)\n",
    "    c_buf = cl.Buffer(context, mf.WRITE_ONLY, XtWg.nbytes)\n",
    "\n",
    "    wk = 16\n",
    "    TS = 16\n",
    "    local = (TS, 1)\n",
    "    # local_buf_size = local[0]*local[1]*np.int32(4)\n",
    "    global_size = (np.int32(m), np.int32(k))\n",
    "\n",
    "    # local = tuple(map(int, local))\n",
    "    # global_size = tuple(map(int, global_size))\n",
    "\n",
    "\n",
    "    # kernel = program.matvecmul\n",
    "    kernel = program.gemv2\n",
    "    kernel.set_arg(0, np.int32(m))\n",
    "    kernel.set_arg(1, np.int32(n))\n",
    "    kernel.set_arg(2, a_buf)\n",
    "    kernel.set_arg(3, b_buf)\n",
    "    kernel.set_arg(4, c_buf)\n",
    "    # kernel.set_arg(5, local_buf_size)\n",
    "    \n",
    "    # kernel.set_arg(5, work_buf)\n",
    "    \n",
    "    # kernel.set_arg(4, np.int32(k))\n",
    "    # kernel.set_arg(5, c_buf)\n",
    "\n",
    "    event = cl.enqueue_nd_range_kernel(queue, kernel, global_size, local)\n",
    "\n",
    "    # event = program.matmul(queue, global_size, local,\n",
    "    #                         np.int32(a.shape[1]), np.int32(b.shape[1]), np.int32(b.shape[0]),\n",
    "    #                         a_buf, b_buf, c_buf)\n",
    "\n",
    "    event.wait()\n",
    "    cl.enqueue_copy(queue, XtWg, c_buf)\n",
    "    a = A\n",
    "    b = XtWg\n",
    "    m, n = np.shape(a)\n",
    "    k = 1\n",
    "    elta = np.empty(m).astype(np.float32)\n",
    "    mf = cl.mem_flags\n",
    "    a_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = a)\n",
    "    b_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = b)\n",
    "    c_buf = cl.Buffer(context, mf.WRITE_ONLY, elta.nbytes)\n",
    "\n",
    "\n",
    "    wk = 16\n",
    "    TS = 16\n",
    "    local = (TS, 1)\n",
    "    # local_buf_size = local[0]*local[1]*np.int32(4)\n",
    "    global_size = (np.int32(m), np.int32(k))\n",
    "\n",
    "    # local = tuple(map(int, local))\n",
    "    # global_size = tuple(map(int, global_size))\n",
    "\n",
    "\n",
    "    # kernel = program.matvecmul\n",
    "    kernel = program.gemv2\n",
    "    kernel.set_arg(0, np.int32(m))\n",
    "    kernel.set_arg(1, np.int32(n))\n",
    "    kernel.set_arg(2, a_buf)\n",
    "    kernel.set_arg(3, b_buf)\n",
    "    kernel.set_arg(4, c_buf)\n",
    "    # kernel.set_arg(5, local_buf_size)\n",
    "    # kernel.set_arg(5, work_buf)\n",
    "    \n",
    "    # kernel.set_arg(4, np.int32(k))\n",
    "    # kernel.set_arg(5, c_buf)\n",
    "\n",
    "    event = cl.enqueue_nd_range_kernel(queue, kernel, global_size, local)\n",
    "\n",
    "    # event = program.matmul(queue, global_size, local,\n",
    "    #                         np.int32(a.shape[1]), np.int32(b.shape[1]), np.int32(b.shape[0]),\n",
    "    #                         a_buf, b_buf, c_buf)\n",
    "\n",
    "    event.wait()\n",
    "    cl.enqueue_copy(queue, elta, c_buf)\n",
    "\n",
    "    # delta[i] = lr*(A @ XtWg) #.flatten() # O(p^2) \n",
    "    delta[i] = lr * elta\n",
    "    a = X\n",
    "    b = delta[i]\n",
    "    m, n = np.shape(a)\n",
    "    k = 1\n",
    "    ta = np.empty(m).astype(np.float32)\n",
    "    mf = cl.mem_flags\n",
    "    a_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = a)\n",
    "    b_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = b)\n",
    "    c_buf = cl.Buffer(context, mf.WRITE_ONLY, ta.nbytes)\n",
    "\n",
    "    TS = 16\n",
    "    local_size = (1, TS)\n",
    "    # local_buf_size = np.int32(local[0]*local[1])\n",
    "    global_size = (np.int32(m), np.int32(k))\n",
    "    if global_size[0] % local_size[0] != 0:\n",
    "      global_size = (global_size[0] + local_size[0] - global_size[0] % local_size[0], global_size[1])\n",
    "    if global_size[1] % local_size[1] != 0:\n",
    "      global_size = (global_size[0], global_size[1] + local_size[1] - global_size[1] % local_size[1])\n",
    "\n",
    "    # local = tuple(map(int, local))\n",
    "    # global_size = tuple(map(int, global_size))\n",
    "\n",
    "\n",
    "    # kernel = program.matvecmul\n",
    "    kernel = program.gemv3\n",
    "    kernel.set_arg(0, np.int32(m))\n",
    "    kernel.set_arg(1, np.int32(n))\n",
    "    kernel.set_arg(2, a_buf)\n",
    "    kernel.set_arg(3, b_buf)\n",
    "    kernel.set_arg(4, c_buf)\n",
    "    # kernel.set_arg(5, local_buf_size)\n",
    "\n",
    "    event = cl.enqueue_nd_range_kernel(queue, kernel, global_size, local_size)\n",
    "\n",
    "    # event.wait()\n",
    "    # cl.enqueue_copy(queue, ta, c_buf)\n",
    "    # eta[i] = X @ delta[i]\n",
    "    eta[i] = ta # O(np)\n",
    "    \n",
    "    rss[i] = np.sum((g-eta[i])**2)\n",
    "\n",
    "  ind = np.argmin(rss)\n",
    "  # Update model\n",
    "  # print(np.shape(delta[ind]))\n",
    "  final_coefs[ind] += delta[ind]\n",
    "  g -= eta[ind]\n",
    "\n",
    "  # benchmark.mean()\n",
    "  benchmark_GPU.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 32)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_matmul = \"\"\"\n",
    "#define TSM 128                // The tile-size in dimension M\n",
    "#define TSN 128                // The tile-size in dimension N\n",
    "#define TSK 16                 // The tile-size in dimension K\n",
    "#define WPTM 8                 // The work-per-thread in dimension M\n",
    "#define WPTN 8                 // The work-per-thread in dimension N\n",
    "#define RTSM (TSM/WPTM)        // The reduced tile-size in dimension M\n",
    "#define RTSN (TSN/WPTN)        // The reduced tile-size in dimension N\n",
    "#define LPTA ((TSK*TSM)/(RTSM*RTSN)) // Loads-per-thread for A\n",
    "#define LPTB ((TSK*TSN)/(RTSM*RTSN)) // Loads-per-thread for B\n",
    "\n",
    "// Use 2D register blocking (further increase in work per thread)\n",
    "__kernel void matmul(const int M, const int N, const int K,\n",
    "                      const __global float* A,\n",
    "                      const __global float* B,\n",
    "                      __global float* C) {\n",
    "    \n",
    "    // Thread identifiers\n",
    "    const int tidm = get_local_id(0); // Local row ID (max: TSM/WPTM)\n",
    "    const int tidn = get_local_id(1); // Local col ID (max: TSN/WPTN)\n",
    "    const int offsetM = TSM*get_group_id(0); // Work-group offset\n",
    "    const int offsetN = TSN*get_group_id(1); // Work-group offset\n",
    " \n",
    "    // Local memory to fit a tile of A and B\n",
    "    __local float Asub[TSK][TSM];\n",
    "    __local float Bsub[TSN][TSK+2];\n",
    " \n",
    "    // Allocate register space\n",
    "    float Areg;\n",
    "    float Breg[WPTN];\n",
    "    float acc[WPTM][WPTN];\n",
    " \n",
    "    // Initialise the accumulation registers\n",
    "    for (int wm=0; wm<WPTM; wm++) {\n",
    "        for (int wn=0; wn<WPTN; wn++) {\n",
    "            acc[wm][wn] = 0.0f;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Loop over all tiles\n",
    "    int numTiles = K/TSK;\n",
    "    for (int t=0; t<numTiles; t++) {\n",
    " \n",
    "        // Load one tile of A and B into local memory\n",
    "        for (int la=0; la<LPTA; la++) {\n",
    "            int tid = tidn*RTSM + tidm;\n",
    "            int id = la*RTSN*RTSM + tid;\n",
    "            int row = id % TSM;\n",
    "            int col = id / TSM;\n",
    "            int tiledIndex = TSK*t + col;\n",
    "            Asub[col][row] = A[tiledIndex*M + offsetM + row];\n",
    "            Bsub[row][col] = B[tiledIndex*N + offsetN + row];\n",
    "        }\n",
    "        \n",
    "        // Synchronise to make sure the tile is loaded\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    " \n",
    "        // Loop over the values of a single tile\n",
    "        for (int k=0; k<TSK; k++) {\n",
    " \n",
    "            // Cache the values of Bsub in registers\n",
    "            for (int wn=0; wn<WPTN; wn++) {\n",
    "                int col = tidn + wn*RTSN;\n",
    "                Breg[wn] = Bsub[col][k];\n",
    "            }\n",
    " \n",
    "            // Perform the computation\n",
    "            for (int wm=0; wm<WPTM; wm++) {\n",
    "                int row = tidm + wm*RTSM;\n",
    "                Areg = Asub[k][row];\n",
    "                for (int wn=0; wn<WPTN; wn++) {\n",
    "                    acc[wm][wn] += Areg * Breg[wn];\n",
    "                }\n",
    "            }\n",
    "        }\n",
    " \n",
    "        // Synchronise before loading the next tile\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "    }\n",
    " \n",
    "    // Store the final results in C\n",
    "    for (int wm=0; wm<WPTM; wm++) {\n",
    "        int globalRow = offsetM + tidm + wm*RTSM;\n",
    "        for (int wn=0; wn<WPTN; wn++) {\n",
    "            int globalCol = offsetN + tidn + wn*RTSN;\n",
    "            C[globalCol*M + globalRow] = acc[wm][wn];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_matmul_global = \"\"\"\n",
    "#pragma OPENCL EXTENSION cl_khr_fp64: enable\n",
    "\n",
    "__kernel void matmul(__global float* C, \n",
    "          __global float* A, \n",
    "          __global float* B, \n",
    "          const int wA, const int wB){\n",
    "  \n",
    "   int tile_x = get_global_id(0); \n",
    "   int tile_y = get_global_id(1);\n",
    " \n",
    "   // value stores the element that is computed by the thread\n",
    "   float value = 0;\n",
    "   for (int k = 0; k < wA; ++k){\n",
    "      float elementA = A[tile_y * wA + k];\n",
    "      float elementB = B[k * wB + tile_x];\n",
    "      value += elementA * elementB;\n",
    "\n",
    "      barrier(CLK_LOCAL_MEM_FENCE);\n",
    "   }\n",
    " \n",
    "   // Write the matrix to device memory each thread writes one element\n",
    "   C[tile_y * wA + tile_x] = value;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.int32(2**12)\n",
    "m = n\n",
    "k = n\n",
    "\n",
    "a = np.random.rand(m, n).astype(np.float32)\n",
    "b = np.random.rand(n, k).astype(np.float32)\n",
    "c = np.empty_like(np.random.rand(m,k).astype(np.float32))\n",
    "\n",
    "mf = cl.mem_flags\n",
    "a_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = a)\n",
    "b_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = b)\n",
    "c_buf = cl.Buffer(context, mf.WRITE_ONLY, c.nbytes)\n",
    "\n",
    "\n",
    "TS = 16\n",
    "local = (TS, TS)\n",
    "global_size = (m, n)\n",
    "\n",
    "# local = tuple(map(int, local))\n",
    "# global_size = tuple(map(int, global_size))\n",
    "\n",
    "\n",
    "kernel = program.matmul\n",
    "\n",
    "kernel.set_arg(0, c_buf)\n",
    "kernel.set_arg(1, a_buf)\n",
    "kernel.set_arg(2, b_buf)\n",
    "kernel.set_arg(3, m)\n",
    "kernel.set_arg(4, k)\n",
    "# kernel.set_arg(5, c_buf)\n",
    "\n",
    "event = cl.enqueue_nd_range_kernel(queue, kernel, global_size, local)\n",
    "\n",
    "# event = program.matmul(queue, global_size, local,\n",
    "#                         np.int32(a.shape[1]), np.int32(b.shape[1]), np.int32(b.shape[0]),\n",
    "#                         a_buf, b_buf, c_buf)\n",
    "\n",
    "event.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1008.2011 , 1021.35754, 1018.945  , ..., 1024.4844 , 1006.6604 ,\n",
       "        1017.56805],\n",
       "       [1016.3794 , 1021.7331 , 1018.2468 , ..., 1010.4697 , 1010.12665,\n",
       "        1020.1729 ],\n",
       "       [1019.67413, 1030.9456 , 1030.3876 , ..., 1035.0476 , 1022.8908 ,\n",
       "        1023.09827],\n",
       "       ...,\n",
       "       [1014.7698 , 1012.31635, 1008.79425, ..., 1013.1611 , 1007.46075,\n",
       "        1020.8824 ],\n",
       "       [1020.79803, 1023.55304, 1018.0205 , ..., 1026.9062 , 1009.5984 ,\n",
       "        1019.94403],\n",
       "       [1010.64594, 1008.86414, 1014.6246 , ..., 1019.57306, 1021.329  ,\n",
       "        1008.7856 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.enqueue_copy(queue, c, c_buf)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.dot(a,b))\n",
    "print(np.matmul(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(np.matmul(a,b), c, decimal=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_matmul = \"\"\"\n",
    "#define BLOCK_SIZE 16\n",
    "#define global_idx(x_idx, y_idx, m) (x_idx * m + y_idx)\n",
    "\n",
    "#define WPT 8\n",
    "#define RBLOCK_SIZE (BLOCK_SIZE/WPT)\n",
    "\n",
    "// -- Uses NDRange Kernel with Local Memory and 2D Register tiling\n",
    "// M, N, P can be arbitrary sizes\n",
    "__kernel __attribute__((reqd_work_group_size(BLOCK_SIZE / WPT, BLOCK_SIZE / WPT, 1)))\n",
    "void matmul(\n",
    "      __global float* restrict A,\n",
    "      __global float* restrict B,\n",
    "      __global float* restrict C,\n",
    "      __const int M,\n",
    "      __const int N,\n",
    "      __const int P,\n",
    "      __const int M_,\n",
    "      __const int N_,\n",
    "      __const int P_)\n",
    "{\n",
    "    const int row = get_local_id(0);\n",
    "    const int col = get_local_id(1);\n",
    "    const int m = BLOCK_SIZE*get_group_id(0) + row;\n",
    "    const int p = BLOCK_SIZE*get_group_id(1) + col;\n",
    "    __local float A_local[BLOCK_SIZE][BLOCK_SIZE];\n",
    "    __local float B_local[BLOCK_SIZE][BLOCK_SIZE];\n",
    "    \n",
    "    float Areg;\n",
    "    float Breg[WPT];\n",
    "    float acc[WPT][WPT];\n",
    "    for(int wm=0; wm<WPT; wm++){\n",
    "        for(int wn=0; wn<WPT; wn++){\n",
    "            acc[wm][wn] = 0.0f;\n",
    "        }\n",
    "    }\n",
    "    const int numTiles = N_/BLOCK_SIZE;\n",
    "    #pragma unroll\n",
    "    for (int t=0; t<numTiles; t++) {\n",
    "        for (int wm=0; wm<WPT; wm++){\n",
    "            for (int wn=0; wn<WPT; wn++){\n",
    "                const int r = BLOCK_SIZE*t + row;\n",
    "                const int c = BLOCK_SIZE*t + col;\n",
    "                if(((m + wm*RBLOCK_SIZE) < M) && ((c + wn*RBLOCK_SIZE) < N)){\n",
    "                    A_local[row + wm*RBLOCK_SIZE][col + wn*RBLOCK_SIZE] = A[(m + wm*RBLOCK_SIZE)*N + (c + wn*RBLOCK_SIZE)];\n",
    "                } else {\n",
    "                    A_local[row + wm*RBLOCK_SIZE][col + wn*RBLOCK_SIZE] = 0.0;\n",
    "                }\n",
    "\n",
    "                if(((p + wn*RBLOCK_SIZE) < P) && ((r + wm*RBLOCK_SIZE) < N)){\n",
    "                    B_local[row + wm*RBLOCK_SIZE][col + wn*RBLOCK_SIZE] = B[(r + wm*RBLOCK_SIZE)*P + (p + wn*RBLOCK_SIZE)];\n",
    "                } else {\n",
    "                    B_local[row + wm*RBLOCK_SIZE][col + wn*RBLOCK_SIZE] = 0.0;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "        #pragma unroll BLOCK_SIZE\n",
    "        for (int k=0; k<BLOCK_SIZE; k++){\n",
    "            for (int wn=0; wn<WPT; wn++){\n",
    "                Breg[wn] = B_local[k][col + wn*RBLOCK_SIZE];\n",
    "            }\n",
    "            for (int wm=0; wm<WPT; wm++){\n",
    "                Areg = A_local[row + wm*RBLOCK_SIZE][k];\n",
    "                for (int wn=0; wn<WPT; wn++){\n",
    "                    acc[wm][wn] += Areg * Breg[wn];\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "    }\n",
    "    for (int wm=0; wm<WPT; wm++){\n",
    "        for (int wn=0; wn<WPT; wn++){\n",
    "            if(((m + wm*RBLOCK_SIZE) < M) && ((p + wn*RBLOCK_SIZE) < P)){\n",
    "                C[(m + wm*RBLOCK_SIZE)*P + (p + wn*RBLOCK_SIZE)] = acc[wm][wn];\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['PYOPENCL_COMPILER_OUTPUT'] = '0'\n",
    "# os.environ['PYOPENCL_CTX'] = '0:1'\n",
    "\n",
    "class Timer:\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end = time.time()\n",
    "        self.interval = self.end - self.start\n",
    "        \n",
    "def roundUp(numToRound, multiple):\n",
    "    if (multiple == 0):\n",
    "        return numToRound\n",
    "    remainder = numToRound % multiple\n",
    "    if (remainder == 0):\n",
    "        return numToRound\n",
    "    return numToRound + multiple - remainder\n",
    "BLOCK_SIZE = 32\n",
    "WPT = 8\n",
    "\n",
    "mult = 3\n",
    "m, n, k = 3*(10**mult), 4*(10**mult), 5*(10**mult)\n",
    "m_, n_, k_ = roundUp(m, BLOCK_SIZE), roundUp(n, BLOCK_SIZE), roundUp(k, BLOCK_SIZE)\n",
    "a = np.random.randn(m, n).astype(np.float32)\n",
    "b = np.random.randn(n, k).astype(np.float32)\n",
    "\n",
    "\n",
    "program = cl.Program(context, gpu_matmul).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np:  0.3036017417907715\n",
      "py:  0.29758572578430176\n",
      "cl:  0.5545623302459717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3000, 5000), 3000, 4000, 5000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_times, py_times, cl_times = [], [], []\n",
    "\n",
    "# ctx = cl.create_some_context()\n",
    "# queue = cl.CommandQueue(ctx)\n",
    "mf = cl.mem_flags\n",
    "a_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = a)\n",
    "b_buf = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = b)\n",
    "\n",
    "start = time.time()\n",
    "c = a.dot(b)\n",
    "end = time.time()\n",
    "print('np: ', end - start)\n",
    "np_times.append(end - start)\n",
    "start = time.time()\n",
    "c = a @ b\n",
    "end = time.time()\n",
    "print('py: ', end - start)\n",
    "py_times.append(end - start)\n",
    "\n",
    "c_res = np.zeros_like(c)\n",
    "c_buf = cl.Buffer(context, mf.WRITE_ONLY, c_res.nbytes)\n",
    "c.shape\n",
    "\n",
    "with Timer() as t:\n",
    "    event = program.matmul(queue, (m_ // WPT , k_ // WPT), (BLOCK_SIZE // WPT, BLOCK_SIZE // WPT), \n",
    "                     a_buf, b_buf, c_buf,\n",
    "                     np.int32(m), np.int32(n), np.int32(k),\n",
    "                     np.int32(m_), np.int32(n_), np.int32(k_))\n",
    "    event.wait()\n",
    "print('cl: ', t.interval)\n",
    "cl_times.append(t.interval)\n",
    "cl.enqueue_copy(queue, c_res, c_buf)\n",
    "\n",
    "c_res.shape, m, n, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(c_res, c, decimal=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpcpy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
